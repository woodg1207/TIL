[toc]



## 1강

- 블록체인의 가치

많은 정보들이 쌓임 -> 정보를 어떻게 교환하느냐

- 제2의 인터넷을 여는것 - 아직은 아니다
- 기술 : 새로운일이 일어날 때마다 노드들이 가진 블록체인을 업데이트, 무결성을 유지하도록 하는 분산형 거래시스템
- 

퍼블릭 블록체인, 프라이빗 블록체인

누구나 참여  		, 허가된 노드만 참여



해시함수 : 암호화

P2P network

블록체인 : 중간의 데이터를 바꾸면 해시값이 바뀌면서 다음 블록도 바뀌게 돼 데이터를 변화시킬수없음

합의 알고리즘(Consensus algo)

스마트 컨트랙트 - 이더리움에서 추가됨



암호화폐 : 국가에서 인정을 하느냐?

- 비즈니스 도메인 활성화 코인
- sns : 스팀잇(게시물을 올리면 환전 가능한 암호화 화폐를 주는것) - 게시글에대한 보상
- Cloud : 콘텐츠를 탈중앙화 시키고 인센티브를 통해 네트워크가 운영되는 클라우드 스토리지 서비스(세계의 남아있는 저장공간을 같이쓰고 이에 따른 보상)
- IoTA : 사물인터넷과 블록체인을 융합한 새로운 플랫폼(M2M payment)

헤르만 지몬 교수

모든것이 디지털화는 될수없지만 디지털화 할수있는것은 모두 디지털화



비금융 분야에서의 사용

- 전자문서관리, 인증권한 관리, 디지털 신분증

- 부동산 거래시장, 다이아몬드 인증/ 거래, 금/은 거래

- 서로간의 신뢰가 필요한 모든 경우들 (유통)

slock it : 스마트 도어락 



공유경제 사회를 만들때

에너지 생성 : 개인이 에너지를 생성함 이를 옆집에 나눠줄수도있음 이때 블록체인으로 함



기업의 블록체인 이용

코닥 

블록체인을 이용한 사진 저작권 정보 저장 및 사진 거래 플랫폼

토요타

블록체인을 이용한 차량공유 플랫폼

월마트

농축산물 유통과정 저장

에어버스

스마트 계약을 통한 각국협력 업체와의 거래 및 설계도 유출 방지

도쿄 전력

개인간의 태양광 에너지 거래가능(블록체인을 이용한 에너지 거래 플랫폼)



## 2강

스마트 컨트랙트

이더리움 소개

- 분산어플리케이션을 위한 플랫폼을 표방
- 비트코인을 개선, 발전시킨 스마트컨트랙트
- 이더 : 이더리움의 화폐

분산화된 상태전이 머신



이더리움의 계정

- 외부소유 계정
  - 잔액유지, 개인키를 통한 주소 관리
  - ETH 전송, 컨트랙트 실행을 위한 거래 전송가능
  - 컨트랙트 코드를 갖고있지 않음 (빈 문자열 hash값)
- 컨트랙트 계정
  - 주소는 있으나 개인키가 없음
  - 컨트랙트 코드를 보유
  - 거래나 메시지를 수신하면 보유하고 있는 컨트랙트 코드를 실행



이더리움 구성요소

- 주소 생성
- 상태
  - 잔액, 기타 정보를 갖는 계정들의 집합

- 이더리움의 상태 전이
  - 거래 내역 추가 시 상태전이 발생
- 트랜잭션의 종류
  -  트랜잭션 (EOA에서 다른 EOA, EOA에서 스마트 컨트랙트)
    - 서명된 메시지 사용
  - 내부 트랜잭션(스마트컨트랙트에서 다른 스마트컨트랙트, 스마트컨트랙트에서 다른 EOA)
    - 서명되지 않은 메시지
    - 블록체인에 별도로 저장되지 않음
- 트랜잭션 리시트
  - 트랜잭션의 실행결과를 기록
- 블록

- 엉클 블록
  - 채굴난이도가 낮아 메인체인에 연결되지 못한 블록
- PoW(작업증명)
  - 계산은 어렵게, 검증은 쉽게
- PoS(지분 증명)
  - PoW의  문제점 개선
  - 이더리움은 Casper를 통해 PoS로 전환 중
- Casper FFG
  - PoW+PoS의 하이브리드 방식
- 스마트 컨트랙트
  - 계약을 코드화 시키고자하는 것
  - Solidity : 현재 가장많이 사용되고 있는 이더리움 스마트 컨트랙트 언어
  - SERPENT : 초창기 이더리움의 스마트 컨트랙트 언어
  - LLL : 어셈블리 언어와 유사
- 스마트 컨트랙트 배포
- 가스 
  - 이더리움을 움직이게하는 기본단위
  - 트랜잭션, 스마트 컨트랙트를 위한 수수료
  - 트랜잭션의 처리속도 변경가능 낮을수록 빨리 처리됨
- 가스 동작 방식
  - 연산에따른 처음 가스에서의 빼기처리
  - 중간에 가스를 다사용하면 롤백
  - 악의 적인 사용을 막고, 가벼운 연산을 시키기 위해서사용
- 계정, 트랜잭션의 생성 -> 서명 -> 검증 -> 채굴



EVM (Ethereum Virtual Machine)

- 이더리움 스마트 컨트랙트를 실행하기 위한 가상 머신
- 특징
  - 튜링 완전 머신, 스택 기반구조, 32Byte 메모리
  - 이더리움주소 연산(160bit), 256bit 암호와 알고리즘 등 이더리움 과련 구조 연산에 최적화
- 모든 동작을 수행하기 위해서는 사전에 가스가 지불되어야 함
  - 이는 DoS 공격을 방지하기 위함
- EVM의 프로그램은 내부에서만 실행되고 가상머신의 HOST 환경에는 접근 불가
- EVM 간 메시지를 통해 데이터를 송수신 할 수있음
- 결정적(Deterministic) 머신 -> 때문에 항상 동일한 상태를 반환



EVM stack

- 이더리움의 모든 연산은 스택에서 수행
- 데이터, 연산의 임시 값 역시 스택에 저장



EVM Memory

- 스마트 컨트랙트 호출 시 생성
- 함수의 매개변수, 지역 변수 및 반환값 등을 임시적을 저장
- 일반적인 RAM과 마찬가지로 휘발성



### 솔리디티 개요

- 이더리움 스마트 컨트랙트 언어의 종류
  - 가장많이 활용되는 언어
  - Java와 유사한 문법
- 특징
  - 객체지향 언어
    - class = Contract(Camel Case)
    - Object instance = EVM에 배포된 스마트 컨트랙트
  - 정적타입 언어
    - 다음 노드의 주소를 저장하는 자료구조
  - 스택기반으로 동작하는 EVM 상에서 구동



솔리디티 스마트 컨트랙트의 기본구조

- 상태변수 정의 부분
  - 컨트랙트에 저장할 상태변수들의 정의
  - 이더리움에 Key:Value 형태로 저장(EVM Storage)
  - 가스소모가 타 연산에 비해 많이 소모
- 접근제어 가능
  - 상태변수의 기본접근제어은 internal
  - public : 모든 함수, 컨트랙트에서 접근 가능
  - internal : 컨트랙트, 상속하는 컨트랙트 내부에서만 접근 가능
  - private : 컨트랙트 내부에서만 접근 가능
  - external : 컨트랙트 내/외부에서 접근 가능하나 상속은 불가능
- 함수 정의 부분
  - 컨트랙트, 외부 컨트랙트, EOA에서 호출할 수 있는 함수를 정의
- 접근제어 가능
  - 함수의 기본접근 제어는 public
  - public : EOA, 컨트랙트 내부, 외부 컨트랙트에서 호출 가능
  - internal : 컨트랙트 내부, 상속하는 컨트랙트 내부에서만 호출 가능
  - private : 컨트랙트 안에서만 호출 가능( 상속 X)
  - external : EOA에서만 호출 가능
- 함수의 종류
  - view : 상태를 write 하지 않는 함수
  - pure : 상태를 read/write 하지 않는 함수
  - fallback : 함수이름, 매개변수, 반환값이 존재하지 않는 함수, 컨트랙트의 함수 호출 시 해당 함수가 존재하지 않을 때 호출됨
  - modifier 함수의 행위를 변경
  - payable : 이더를 송금해야만 호출 가능한 함수



## 3강 big data



Clustering :  추천 시스템

- 데이터를 유사도에 따라 K개수로 나누는 것
- 그룹을 나뉘었을때 유저가 속한 그룹에서 해당안되는 부분을 추천해줄수 있음
- 

클러스터링 측정    sum((center - x)**2)

파티셔널 알고리즘



근사적으로 일부만 사용한다.



k-means clustering

- 단점 
  - 크거나 작을경우 정확하지 않음
  - outlier 때문에 문제가 생김 정확하지 않은 평균점
  - non - spherical shapes

k-Medoids 평균점을 실제 있는 점으로 만든다.



Hierarchical Clustering

- bottom up  : N개의 집합중 가까운 집합들을 병합하면서 k개에 맞춤
- top down

- 거리계산에 따라 성능을 나눔.
  - single link
  - complete link
  - average link
  - mean link
  - centroid link



DBSCAN Clustering 



## 4강

 EM Clustering

- generative model(생성 모델)

그럼 데이터를 통해서 생성모델을 알수있나?

-  
- 생성모델을 만들고 그것의 params를 만들고 확률값을 계산해서 가장 높은 생성모델을 사용



Probabilistic latent Semantic indexing(PLSI) 를 활용한 EM Algorithm

문서들을 주제로 클러스터링

글을 쓸때 각 주제선택 -> 주제마다 단어들의 확률을 보는것 

distribution



likelihood function for EM algorithm



주제가 무엇에 관한건지 알수 있음.



Twitobi

각각의 follower를 추천해줄수 있음 



나의 주제나 혹은 내가 팔로우하는 사람의 주제에 대해서 분석을 할수있음.





Recommendation System

- Content based filtering method

  - item 이나 product 등과 같은 actual content를 이용
  - 각 item간의 similarity를 이용해서 추천

- Collaborative filtering method

  - 각각의 유저는 비슷한 다른 유저와 동일하게 행동한다는 가정 - 다른 유저들이 추천에 영향을 미침.
    - 다른 유저들의 의견을 이용함 : usage 또는 preference pattern을 이용

  - User가 직접 점수를 매긴 item 들에 대한  rating을 이용해서 추천
  - Memory based method
    - Operates over the entire database to make predictions
    - 대부분의 work이 offline으로 진행
    - ex) 과거의 rating에 base 해서 rating prediction을 함
  - Model based method
    - User database를 이용해서 prediction 을 위한 model을 생성
    - 과거의 rating 에 base 해서 model을 만들고 그 모델에 의해서 unseen item에 rating을 함
    - Model을 만들기 위해서 대부분의 work이 offline으로 진행



## 5강 

AI, machine learning

ML VS big data

- 빅데이터는 데이터가 많고, 이 데이터에 대한 여러 방법론들이 존재 하는데 이중 하나가 ML이다.

ML vs DataMining

- 데이터 자체의 차이
- 데이터 마이닝 : 정형데이터(성별, 주소등)
- ML : 비정형 데이터(img, text data)를 분석함

AI vs ML

- ML은 AI의 일부분
- AI : 컴퓨터가 사람의 지능을 갖는것
- AI 중 데이터에 의존하는 방법이 ML, 통계적인 방법

ML vs Statistics

- ML : 통계학을 갖고 만드는것



ML에서 다루는 문제들

- Supervised Learning : 지도학습
  - 대표적인 ML
  - 이미지 라벨(정답)을 통해서 컴퓨터가 인식(분류)을 하는 것
  - Classification
    - 선형, 비선형 모델
    - 비선형 모델
      - Data에 대해서 계속 질문을 하는것.

- Unsupervised Learning : 비지도 학습
  - 이미지 라벨(정답)이 없는 이미지를 통해 컴퓨터가 분류를 한다.
  - k-means clustering, DB Scan등을 사용하여 군집화를 한다.
- Representatio Learning  :  딥러닝
  - Deep Neural Network
  - Facial Recognition
    1. 각 픽셀을 보며 색을 찾음.
    2. 각 픽셀에 대한 선을 연결해 선의 색을 찾음.
    3. 조합을 통해 얼굴을 찾아간다. 
  - 하나의 Neural Network를 통해 여러 알고리즘을 사용하여 Facil Recogintion이 가능하게 함.

- Reinforcement Learning : 강화 학습



AI 응용분야

- Visual Intelligence
  - MNIST : 숫자 필기 인식
  - Image Net : 몇 천개의 class image가 존재. 정확도를 올리기 위해 노력중, 또한 데이터가 부족한 class에 대해서도 정확한 결과를 도출하도록 노력중.
- Language Intelligence 
  - ex) IBM watson
  - 정보를 주고 정보에대해 질문을 하고 그에대한 답을 도출할 수있는지에 대해 연구중
  - Machine Transition : 기계 번역
    - 

## 6강.

##### Linear Regression

- 지도학습
- 데이터의 결과 값을 실수로 나타낼수 있음 (Class로 나누는 것이 아님)
- 가격예측, 소비자의 지출등을 예측할 수 있다. 
- x값에 따른 y값을 구하기 쉽도록 line을 그려준다.

- 비선형일 경우에도 모델링이 가능하다. 

##### Polynomial Regression

- 차수에 따른 복잡한 Line을 구할 수 있다.

##### Multivariate linear regression

- 면으로 분석으하는 경우 (3차원)

##### RSS : Residual Sum of Squares

- 각 선의 정확도들을 찾아주는 식

##### Ridge Regression

- 데이터에 따른 선이 필요 이상으로 복잡(n차)하게 나오게 되는경우 
- 이를 심플하게 만들어 준다. 
- 복잡한 선들의 경우 패널티를 부여해준다.



## 7강.

분류하는 방식

##### Naive Bayes Classifier

- 모형자체를 '왜, 어떻게 분류했는지'에대해서 접근하는 방식
- 많은 연구들 중에서 기본 모형을 사요하기 때문에 사용
- 결과는 좋지 않지만 기준으로 삼는 모델링 방식

- features 
  - 특징, data detail, 성질
- Problems 
  - Digit Recognition
    - 출력은 0~9
    - 픽셀로 이미지를 접근한다. 
    - 각 좌표당 픽셀로 해서 한픽셀의 색이 검정색인지 흰색인지 구별을 한다. 
    - 이에 대한 확률을 통해서 숫자를 구별한다. 
    - 각 숫자의 픽셀의 확률을 통해서 숫자를 구별함.
    - 각 픽셀의 확률은 어떻게 얻어낼 것인가?
      - Traning Data를 통해서 확률을 얻어 낸다.
      - 또는, expert에게 조언을 구하는 방식(숫자외의 다른 분석을 하는 경우)
  - Email Recognition
    - Spam Filter

- 확률 통계로 접근을 한다.

- Naive Bayes for Text
  - Bag of Words Naive Bayes
- Overfitting
  - Test Data의 경우 : 안나오는 데이터가 들어가 있을때 정확한 데이터가 안나올수  있다.
  - Smoothing을 통해 해결.



## 8강.

##### Deep Natural Language Processing

- Word, Sentence, and Document Embedding

- 의미를 추출하는 것이 목표이다 .

-  Word Embedding

  - 단어 하나하나에 대해서 벡터로 표현하는 것.
  - 비슷한 단어들은 방향성을 갖고 있다.
  - 예를 들어 cat, cats의 경우와 dog, dogs의 경우 단수, 복수로 방향성을 갖는데 각각의 cat, dog는 같은 방향성을 갖고 복수형으로 진행한다. 

  - Distributed Representations

    - Many to Many relationship
      - 하나의 컨셉은 많은 뉴런들을 갖을 수 있고
      - 하나의 뉴런은 많은 컨셉을 가질 수 있기 때문에 

  - Distributional Hypothesis

    - 단어는 같은 문장에서 비슷한 문맥을 갖는다. 

  - Word2Vec

    - CBOW
      - 문맥에 있는 단어가 주어지고 가운데 단어가 무엇인지 찾아냄.

    - Skip-Gram
      - 문맥상 옆단어를 찾는 것.

  - Evaluation

    - Word Similarity Task
    - Word Analogy Task

  - Problems of word-level approach

    - Out of vocabularies : Unseen words
      - Morphologically rich language
      - Compositionality of words
    - Quality of vectors assigned to rare words
    - Segmentation issues

  - Subword Information Skip-Gram

    - 단어를 쪼개서 분석한다. 분석 정확도가 더 높음.

  - contextualized Word Embedding

    - 문장을 분석해서 같은 단어라 해도 다른 의미를 해석한다. 
    - 